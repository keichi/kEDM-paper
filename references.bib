@inproceedings{Treibig2010,
author = {Treibig, Jan and Hager, Georg and Wellein, Gerhard},
booktitle = {2010 39th International Conference on Parallel Processing Workshops},
doi = {10.1109/ICPPW.2010.38},
isbn = {978-1-4244-7918-4},
mendeley-groups = {kEDM},
month = {sep},
pages = {207--216},
title = {{LIKWID: A Lightweight Performance-Oriented Tool Suite for x86 Multicore Environments}},
year = {2010}
}
@inproceedings{Natsukawa2017,
author = {Natsukawa, Hiroaki and Koyamada, Koji},
booktitle = {SIGGRAPH Asia 2017 Symposium on Visualization},
doi = {10.1145/3139295.3139303},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Natsukawa, Koyamada - 2017 - Visual analytics of brain effective connectivity using convergent cross mapping.pdf:pdf},
isbn = {9781450354110},
mendeley-groups = {kEDM},
month = {nov},
title = {{Visual analytics of brain effective connectivity using convergent cross mapping}},
year = {2017}
}
@article{Yang2020b,
abstract = {The Roofline performance model provides an intuitive and insightful approach to identifying performance bottlenecks and guiding performance optimization. In preparation for the next-generation supercomputer Perlmutter at NERSC, this paper presents a methodology to construct a hierarchical Roofline on NVIDIA GPUs and extends it to support reduced precision and Tensor Cores. The hierarchical Roofline incorporates L1, L2, device memory, and system memory bandwidths into one single figure, and it offers more profound insights into performance analysis than the traditional DRAM-only Roofline. We use our Roofline methodology to analyze three proxy applications: GPP from BerkeleyGW, HPGMG from AMReX, and conv2d from TensorFlow. In doing so, we demonstrate the ability of our methodology to readily understand various aspects of performance and performance bottlenecks on NVIDIA GPUs and motivate code optimizations.},
author = {Yang, Charlene and Kurth, Thorsten and Williams, Samuel},
doi = {10.1002/cpe.5547},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Yang, Kurth, Williams - 2020 - Hierarchical Roofline analysis for GPUs Accelerating performance optimization for the NERSC-9 Perlmutter.pdf:pdf},
issn = {15320634},
journal = {Concurrency Computation},
keywords = {Cray,NVIDIA GPU,Roofline,code optimization,performance analysis,tensor core},
mendeley-groups = {kEDM},
month = {oct},
number = {20},
title = {{Hierarchical Roofline analysis for GPUs: Accelerating performance optimization for the NERSC-9 Perlmutter system}},
volume = {32},
year = {2020}
}
@article{Chang2017,
abstract = {Natural systems are often complex and dynamic (i.e. nonlinear), making them difficult to understand using linear statistical approaches. Linear approaches are fundamentally based on correlation. Thus, they are ill-posed for dynamical systems, where correlation can occur without causation, and causation may also occur in the absence of correlation. “Mirage correlation” (i.e., the sign and magnitude of the correlation change with time) is a hallmark of nonlinear systems that results from state dependency. State dependency means that the relationships among interacting variables change with different states of the system. In recent decades, nonlinear methods that acknowledge state dependence have been developed. These nonlinear statistical methods are rooted in state space reconstruction, i.e. lagged coordinate embedding of time series data. These methods do not assume any set of equations governing the system but recover the dynamics from time series data, thus called empirical dynamic modeling (EDM). EDM bears a variety of utilities to investigating dynamical systems. Here, we provide a step-by-step tutorial for EDM applications with rEDM, a free software package written in the R language. Using model examples, we aim to guide users through several basic applications of EDM, including (1) determining the complexity (dimensionality) of a system, (2) distinguishing nonlinear dynamical systems from linear stochastic systems, and quantifying the nonlinearity (i.e. state dependence), (3) determining causal variables, (4) forecasting, (5) tracking the strength and sign of interaction, and (6) exploring the scenario of external perturbation. These methods and applications can be used to provide a mechanistic understanding of dynamical systems.},
author = {Chang, Chun Wei and Ushio, Masayuki and hao Hsieh, Chih},
doi = {10.1007/s11284-017-1469-9},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Chang, Ushio, Hsieh - 2017 - Empirical dynamic modeling for beginners.pdf:pdf},
issn = {14401703},
journal = {Ecological Research},
keywords = {Embedding,Forecast,Interaction,State dependence,State space reconstruction},
mendeley-groups = {kEDM},
month = {nov},
number = {6},
pages = {785--796},
publisher = {Springer Tokyo},
title = {{Empirical dynamic modeling for beginners}},
volume = {32},
year = {2017}
}
@article{Edwards2014,
author = {{Carter Edwards}, H. and Trott, Christian R. and Sunderland, Daniel},
doi = {10.1016/j.jpdc.2014.07.003},
issn = {07437315},
journal = {Journal of Parallel and Distributed Computing},
mendeley-groups = {kEDM},
month = {dec},
number = {12},
title = {{Kokkos: Enabling manycore performance portability through polymorphic memory access patterns}},
volume = {74},
year = {2014}
}
@inproceedings{Schubert2018,
author = {Schubert, Erich and Gertz, Michael},
booktitle = {Proceedings of the 30th International Conference on Scientific and Statistical Database Management},
doi = {10.1145/3221269.3223036},
isbn = {9781450365055},
mendeley-groups = {kEDM},
month = {jul},
pages = {1--12},
title = {{Numerically stable parallel computation of (co-)variance}},
year = {2018}
}
@inproceedings{Deakin2019,
abstract = {Previous studies into performance portability have typically analysed a single application (and its various imple- mentations) in isolation. In this study we explore the wider landscape of performance portability by considering a number of applications from across the space of dwarfs, written in multiple parallel programming models, and across a diverse set of architectures. We apply rigorous performance portability metrics, as defined by Pennycook et al [1]. We believe this is the broadest and most rigorous performance portability study to date, representing a far reaching exploration of the state of performance portability that is achievable today. We will present a summary of the performance portability of each application and programming model across our diverge range of twelve computer architectures, including six different server CPUs from five different vendors, five different GPUs from two different vendors, and one vector architecture. We will conclude with an analysis of the performance portability of key programming models in general, across different application spaces as well across differing architectures, allowing us to comment on more general performance portability principles.},
author = {Deakin, Tom and Mcintosh-Smith, Simon and Price, James and Poenaru, Andrei and Atkinson, Patrick and Popa, Codrin and Salmon, Justin},
booktitle = {Proceedings of P3HPC 2019: International Workshop on Performance, Portability and Productivity in HPC - Held in conjunction with SC 2019: The International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/P3HPC49587.2019.00006},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Deakin et al. - 2019 - Performance Portability across Diverse Computer Architectures.pdf:pdf},
isbn = {9781728160030},
keywords = {mini-app,performance portability,productivity,programming models},
mendeley-groups = {kEDM},
month = {nov},
pages = {1--13},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Performance Portability across Diverse Computer Architectures}},
year = {2019}
}
@unpublished{Yang2020a,
abstract = {This paper surveys a range of methods to collect necessary performance data on Intel CPUs and NVIDIA GPUs for hierarchical Roofline analysis. As of mid-2020, two vendor performance tools, Intel Advisor and NVIDIA Nsight Compute, have integrated Roofline analysis into their supported feature set. This paper fills the gap for when these tools are not available, or when users would like a more customized workflow for certain analysis. Specifically, we will discuss how to use Intel Advisor, RRZE LIKWID, Intel SDE and Intel Amplifier on Intel architectures, and nvprof, Nsight Compute metrics, and Nsight Compute section files on NVIDIA architectures. These tools will be used to collect information for as many memory/cache levels in the memory hierarchy as possible in order to provide insights into application's data reuse and cache locality characteristics.},
archivePrefix = {arXiv},
arxivId = {2009.02449},
author = {Yang, Charlene},
eprint = {2009.02449},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Yang - 2020 - Hierarchical Roofline Analysis How to Collect Data using Performance Tools on Intel CPUs and NVIDIA GPUs.pdf:pdf},
mendeley-groups = {kEDM},
month = {sep},
title = {{Hierarchical Roofline Analysis: How to Collect Data using Performance Tools on Intel CPUs and NVIDIA GPUs}},
url = {http://arxiv.org/abs/2009.02449},
year = {2020}
}
@article{Williams2008,
abstract = {We propose an easy-to-understand, visual performance model that offers insights to programmers and architects on improving parallel software and hardware for floating point computations.},
author = {Williams, Samuel and Waterman, Andrew and Patterson, David},
doi = {10.1145/1498765.1498785},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Williams, Waterman, Patterson - 2008 - Roofline An Insightful Visual Performance Model for Floating-Point Programs and Multicore Archite.pdf:pdf},
journal = {Communications of the ACM},
mendeley-groups = {kEDM},
number = {4},
pages = {65--76},
title = {{Roofline: An Insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures*}},
volume = {52},
year = {2008}
}
@inproceedings{Ma2017,
author = {Ma, Jiayi and Yang, Ming and Han, Xueshan and Li, Zhi},
booktitle = {2017 IEEE Industry Applications Society Annual Meeting},
doi = {10.1109/IAS.2017.8101715},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2017 - Ultra-short-term wind generation forecast based on multivariate empirical dynamic modeling.pdf:pdf},
isbn = {978-1-5090-4894-6},
mendeley-groups = {kEDM},
month = {oct},
title = {{Ultra-short-term wind generation forecast based on multivariate empirical dynamic modeling}},
year = {2017}
}
@inproceedings{Malcolm2012,
abstract = {ArrayFire is a GPU matrix library for the rapid development of general purpose GPU (GPGPU) computing applications within C, C++, Fortran, and Python. ArrayFire contains a simple API and provides full GPU compute capability on CUDA and OpenCL capable devices. ArrayFire provides thousands of GPU-tuned functions including linear algebra, convolutions, reductions, and FFTs as well as signal, image, statistics, and graphics libraries. We will further describe how ArrayFire enables development of GPU computing applications and highlight some of its key functionality using examples of how it works in real code.},
author = {Malcolm, James and Yalamanchili, Pavan and McClanahan, Chris and Venugopalakrishnan, Vishwanath and Patel, Krunal and Melonakos, John},
booktitle = {Modeling and Simulation for Defense Systems and Applications VII},
doi = {10.1117/12.921122},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Malcolm et al. - 2012 - ArrayFire a GPU acceleration platform.pdf:pdf},
isbn = {9780819490810},
issn = {1996756X},
mendeley-groups = {kEDM},
month = {may},
pages = {84030A},
publisher = {SPIE},
title = {{ArrayFire: a GPU acceleration platform}},
volume = {8403},
year = {2012}
}
@inproceedings{mpedm,
author = {Watanakeesuntorn, Wassapon and Takahashi, Keichi and Ichikawa, Kohei and Park, Joseph and Sugihara, George and Takano, Ryousei and Haga, Jason and Pao, Gerald M.},
booktitle = {26th International Conference on Parallel and Distributed Systems (ICPADS 2020)},
file = {:Users/keichi/Library/Application Support/Mendeley Desktop/Downloaded/Watanakeesuntorn et al. - 2020 - Massively Parallel Causal Inference of Whole Brain Dynamics at Single Neuron Resolution.pdf:pdf},
mendeley-groups = {kEDM},
month = {dec},
title = {{Massively Parallel Causal Inference of Whole Brain Dynamics at Single Neuron Resolution}},
year = {2020}
}
